---
title: MQ on IKS
description: MQ on IKS
tabs: ['MQ Overview','MQ on IKS', 'MQ on OpenShift']
---

Social Program Management supports only **IBM MQ LTS on a VM** , when running on IKS. The steps below outline how to do this. In this runbook we will outline the steps to create:

* [Queues](https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.1.0/com.ibm.mq.pro.doc/q003090_.htm)
* [Listeners](https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.1.0/com.ibm.mq.pro.doc/q003300_.htm)
* [Channels](https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.1.0/com.ibm.mq.pro.doc/q003220_.htm)
* [Topics](https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.1.0/com.ibm.mq.pro.doc/q003320_.htm)

<InlineNotification>

**Note:** The MQ version for this runbook verification is  9.1.0 LTS.

</InlineNotification>

For the runbook, two standalone VMs were used as MQ nodes.

### Queue manager names

For runbook configuration, the following naming conversion was used throughout the MQ setup: QM_NamingConvention_AppName. This must be unique, but ensure you change the commands used on this page accordingly.

**Queue Name:**

* QM_minikube_curam

**Channel Name:** This value should be all capitals

CHL_NamingConvention_AppName

* CHL_MINIKUBE_CURAM

**Listeners Name:** This value should be all capitals

LS_NamingConvention_AppName

* LS_MINIKUBE_CURAM

## MQ stages

On both MQ nodes run the following command as root:

```shell
su - mqm # Changing user into mqm
export PATH=/opt/mqm/inst1/bin:$PATH
```

<InlineNotification kind="warning">

**Important!**

Run the export PATH command on both MQ nodes, this command will be used in further commands in the runbook.

</InlineNotification>

## Shared storage

Create the shared storage for our nodes.

<InlineNotification>

**Note:** Run the commands as root.

</InlineNotification>

On the shared node run the following commands:

```shell
mkdir -p /MQHA/logs
mkdir -p /MQHA/qmgrs
mkdir -p /MQHA/scratch
useradd mqha -s /sbin/nologin
chown -R mqha:mqha /MQHA/*
```

Verify that the UID and GUID match the owner ID by running the following command:

```shell
echo "/MQHA  MQ.FQDN(rw,sync,no_wdelay,fsid=0,anonuid=1001,anongid=1001)" >> /etc/exports
```

Start and enable both the nfs service and rpcbind service by running the following commands:

```shell
systemctl start nfs-server.service
systemctl enable nfs-server.service
systemctl start rpcbind
systemctl enable rpcbind
```

On MQ nodes run the following commands:

<InlineNotification>

**Note:** Commands to be run as root.

</InlineNotification>

```shell
echo "SHAREDNODEADDRESS:/MQHA  /MQHA  nfs  defaults  0 0" >> /etc/fstab
systemctl start rpcbind
systemctl enable rpcbind
mkdir -p /MQHA
chmod 1777 /MQHA #Check permissions
mount /MQHA
```

## Create QMs

When creating the queue, start on the secondary node first then move to the primary node.

On the secondary MQ node, run the following commands:

```shell
crtmqm -ld /MQHA/logs -md /MQHA/qmgrs QM_minikube_curam
dspmqinf -o command QM_minikube_curam
```

Save the output of the above command. It should look like the following.

```shell
addmqinf -s QueueManager -v Name=QM_minikube_curam -v Directory=QM_minikube_curam -v Prefix=/var/mqm -v DataPath=/MQHA/qmgrs/QM_minikube_curam
```

Wait for /MQHA/qmgrs/QM_minikube_curam/qm.ini to appear on other node

On the primary MQ node run the following commands:

```shell
addmqinf -s QueueManager -v Name=QM_minikube_curam -v Directory=QM_minikube_curam -v Prefix=/var/mqm -v DataPath=/MQHA/qmgrs/QM_minikube_curam
strmqm -x QM_minikube_curam
```

On the secondary MQ node run the following command:

```shell
strmqm -x QM_minikube_curam
```

## Create queues

On the primary MQ node run the following commands:

```shell
runmqsc QM_minikube_curam <<-EOS
DEFINE QLOCAL(QN.CURAMDEADMESSAGEQUEUE) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
DEFINE QLOCAL(QN.WORKFLOWERROR) BOTHRESH(5) BOQNAME(QN.CURAMDEADMESSAGEQUEUE) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
DEFINE QLOCAL(QN.WORKFLOWENACTMENT) BOTHRESH(5) BOQNAME(QN.WORKFLOWERROR) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
DEFINE QLOCAL(QN.WORKFLOWACTIVITY) BOTHRESH(5) BOQNAME(QN.WORKFLOWERROR) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
DEFINE QLOCAL(QN.DPERROR) BOTHRESH(5) BOQNAME(QN.CURAMDEADMESSAGEQUEUE) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
DEFINE QLOCAL(QN.DPENACTMENT) BOTHRESH(5) BOQNAME(QN.DPERROR) CLWLUSEQ (ANY) DEFBIND (NOTFIXED)
ALTER QMGR CHLAUTH(DISABLED)
ALTER QMGR DEADQ(QN.CURAMDEADMESSAGEQUEUE)
EOS
```

## Create listeners

On the primary MQ node run the following commands:

```shell
runmqsc QM_minikube_curam <<-EOS
DEFINE LISTENER (LS_MINIKUBE_CURAM) TRPTYPE (TCP) CONTROL (QMGR) PORT (1414)
START LISTENER (LS_MINIKUBE_CURAM)
EOS
```

## Create channels

On the primary MQ node run the following command:

* Enter your MQ node names into the commands below

<InlineNotification>

**Note:** CERTLABL expects the value to be lower case ibmwebspheremq + Queue Name
For this example it will be ibmwebspheremqqm_minikube_curam

</InlineNotification>

```shell
runmqsc QM_minikube_curam <<-EOS
DEFINE CHANNEL(CHL_MINIKUBE_CURAM) CHLTYPE(SVRCONN)  TRPTYPE(TCP) MCAUSER('mqm') SSLCIPH (TLS_RSA_WITH_AES_128_CBC_SHA256)  CERTLABL ('ibmwebspheremqqm_minikube_curam') SSLCAUTH (OPTIONAL) REPLACE
DEFINE CHANNEL(CHL_MINIKUBE_CURAM) CHLTYPE(CLNTCONN) TRPTYPE(TCP) CONNAME('Node1(1414),Node2(1414)') QMNAME(QM_minikube_curam) SSLCIPH (TLS_RSA_WITH_AES_128_CBC_SHA256) CERTLABL ('ibmwebspheremqqm_minikube_curam') REPLACE
EOS
```

## Create topics

On the primary MQ node run the following command:

```shell
runmqsc QM_minikube_curam <<-EOS
DEFINE TOPIC (CURAMCACHEINVALIDATIONTOPIC) TOPICSTR (CURAMCACHEINVALIDATIONTOPIC)
ALTER QMGR CONNAUTH('CHECK.PWD')
DEFINE AUTHINFO('CHECK.PWD') AUTHTYPE(IDPWOS) CHCKLOCL(OPTIONAL) CHCKCLNT(OPTIONAL)
EOS
```

## Configure security

The configuration of security is in four parts

* Setting the object type.
* Creating the keystore and certs.
* Updating the certs on both nodes.
* Refreshing security settings.

<InlineNotification>

**Note:** The application pods run as a non-root user (default). This non-root user must exist on both MQ nodes.

</InlineNotification>

On the secondary MQ node run the following command:

```shell
useradd -g 0 -M default && usermod -L default
```

On the primary MQ node run the following commands:

```shell
useradd -g 0 -M default && usermod -L default
runmqsc QM_minikube_curam <<-EOS
SET AUTHREC OBJTYPE(QMGR) PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.DPENACTMENT') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.DPERROR') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.WORKFLOWACTIVITY') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.WORKFLOWENACTMENT') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.WORKFLOWERROR') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(QUEUE) PROFILE('QN.CURAMDEADMESSAGEQUEUE') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(LISTENER) PROFILE('LS_MINIKUBE_CURAM') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(CHANNEL) PROFILE('CHL_MINIKUBE_CURAM') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(CLNTCONN) PROFILE('CHL_MINIKUBE_CURAM') PRINCIPAL('default') AUTHADD(ALL)
SET AUTHREC OBJTYPE(TOPIC) PROFILE('CURAMCACHEINVALIDATIONTOPIC') PRINCIPAL('default') AUTHADD(ALL)
EOS
```

```shell
runmqckm -keydb -create -db /MQHA/qmgrs/QM_minikube_curam/ssl/key.kdb -type cms -pw Passw0rd -stash
runmqakm -cert -create -db /MQHA/qmgrs/QM_minikube_curam/ssl/key.kdb -stashed -label ibmwebspheremqqm_minikube_curam -size 2048 -dn "CN=QM_minikube_curam,O=IBM,C=US" -x509version 3 -expire 365 -sig_alg SHA1WithRSA
runmqakm -cert -extract -db /MQHA/qmgrs/QM_minikube_curam/ssl/key.kdb -stashed -label ibmwebspheremqqm_minikube_curam -target /MQHA/qmgrs/QM_minikube_curam/ssl/key_QM_minikube_curam.arm
runmqakm -cert -export -db /MQHA/qmgrs/QM_minikube_curam/ssl/key.kdb -stashed -label ibmwebspheremqqm_minikube_curam -target /MQHA/qmgrs/QM_minikube_curam/ssl/key_QM_minikube_curam.p12 -target_type pkcs12 -target_pw Passw0rd
```

```shell
openssl pkcs12 -in /MQHA/qmgrs/QM_minikube_curam/ssl/key_QM_minikube_curam.p12 -passin pass:Passw0rd -nocerts -nodes | sed -ne '/-BEGIN PRIVATE KEY-/,/-END PRIVATE KEY-/p' > /MQHA/qmgrs/QM_minikube_curam/ssl/tls.key
openssl pkcs12 -in /MQHA/qmgrs/QM_minikube_curam/ssl/key_QM_minikube_curam.p12 -passin pass:Passw0rd -clcerts -nokeys | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > /MQHA/qmgrs/QM_minikube_curam/ssl/tls.crt
```

```shell
runmqsc QM_minikube_curam <<-EOS
ALTER QMGR CONNAUTH('CHECK.PWD')
DEFINE AUTHINFO('CHECK.PWD') AUTHTYPE(IDPWOS) CHCKLOCL(OPTIONAL) CHCKCLNT(OPTIONAL)
REFRESH SECURITY TYPE(SSL)
REFRESH SECURITY TYPE(AUTHSERV)
REFRESH SECURITY TYPE(CONNAUTH)
EOS
```

After these stages have been run MQ should be configured.

## Clean up QMs/channels/listeners

Used these steps if you are reconfiguring MQ or cleaning up MQ.

On both MQ nodes run the following commands:

```shell
endmqm -w QM_minikube_curam
dltmqm QM_minikube_curam
rmvmqinf QM_minikube_curam
```

On either MQ node run the following commands:

```shell
rm -rf /MQHA/qmgrs/**
rm -rf /MQHA/logs/**
rm -rf /MQHA/scratch
endmqm -w QM_minikube_curam
dltmqm QM_minikube_curam
rmvmqinf QM_minikube_curam
```
